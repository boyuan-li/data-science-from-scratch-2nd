{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 16. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.1 The problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = [(0.7,48000,1),(1.9,48000,0),(2.5,60000,1),(4.2,63000,0),(6,76000,0),(6.5,69000,0),(7.5,76000,0),(8.1,88000,0),(8.7,83000,1),(10,83000,1),(0.8,43000,0),(1.8,60000,0),(10,79000,1),(6.1,76000,0),(1.4,50000,0),(9.1,92000,0),(5.8,75000,0),(5.2,69000,0),(1,56000,0),(6,67000,0),(4.9,74000,0),(6.4,63000,1),(6.2,82000,0),(3.3,58000,0),(9.3,90000,1),(5.5,57000,1),(9.1,102000,0),(2.4,54000,0),(8.2,65000,1),(5.3,82000,0),(9.8,107000,0),(1.8,64000,0),(0.6,46000,1),(0.8,48000,0),(8.6,84000,1),(0.6,45000,0),(0.5,30000,1),(7.3,89000,0),(2.5,48000,1),(5.6,76000,0),(7.4,77000,0),(2.7,56000,0),(0.7,48000,0),(1.2,42000,0),(0.2,32000,1),(4.7,56000,1),(2.8,44000,1),(7.6,78000,0),(1.1,63000,0),(8,79000,1),(2.7,56000,0),(6,52000,1),(4.6,56000,0),(2.5,51000,0),(5.7,71000,0),(2.9,65000,0),(1.1,33000,1),(3,62000,0),(4,71000,0),(2.4,61000,0),(7.5,75000,0),(9.7,81000,1),(3.2,62000,0),(7.9,88000,0),(4.7,44000,1),(2.5,55000,0),(1.6,41000,0),(6.7,64000,1),(6.9,66000,1),(7.9,78000,1),(8.1,102000,0),(5.3,48000,1),(8.5,66000,1),(0.2,56000,0),(6,69000,0),(7.5,77000,0),(8,86000,0),(4.4,68000,0),(4.9,75000,0),(1.5,60000,0),(2.2,50000,0),(3.4,49000,1),(4.2,70000,0),(7.7,98000,0),(8.2,85000,0),(5.4,88000,0),(0.1,46000,0),(1.5,37000,0),(6.3,86000,0),(3.7,57000,0),(8.4,85000,0),(2,42000,0),(5.8,69000,1),(2.7,64000,0),(3.1,63000,0),(1.9,48000,0),(10,72000,1),(0.2,45000,0),(8.6,95000,0),(1.5,64000,0),(9.8,95000,0),(5.3,65000,0),(7.5,80000,0),(9.9,91000,0),(9.7,50000,1),(2.8,68000,0),(3.6,58000,0),(3.9,74000,0),(4.4,76000,0),(2.5,49000,0),(7.2,81000,0),(5.2,60000,1),(2.4,62000,0),(8.9,94000,0),(2.4,63000,0),(6.8,69000,1),(6.5,77000,0),(7,86000,0),(9.4,94000,0),(7.8,72000,1),(0.2,53000,0),(10,97000,0),(5.5,65000,0),(7.7,71000,1),(8.1,66000,1),(9.8,91000,0),(8,84000,0),(2.7,55000,0),(2.8,62000,0),(9.4,79000,0),(2.5,57000,0),(7.4,70000,1),(2.1,47000,0),(5.3,62000,1),(6.3,79000,0),(6.8,58000,1),(5.7,80000,0),(2.2,61000,0),(4.8,62000,0),(3.7,64000,0),(4.1,85000,0),(2.3,51000,0),(3.5,58000,0),(0.9,43000,0),(0.9,54000,0),(4.5,74000,0),(6.5,55000,1),(4.1,41000,1),(7.1,73000,0),(1.1,66000,0),(9.1,81000,1),(8,69000,1),(7.3,72000,1),(3.3,50000,0),(3.9,58000,0),(2.6,49000,0),(1.6,78000,0),(0.7,56000,0),(2.1,36000,1),(7.5,90000,0),(4.8,59000,1),(8.9,95000,0),(6.2,72000,0),(6.3,63000,0),(9.1,100000,0),(7.3,61000,1),(5.6,74000,0),(0.5,66000,0),(1.1,59000,0),(5.1,61000,0),(6.2,70000,0),(6.6,56000,1),(6.3,76000,0),(6.5,78000,0),(5.1,59000,0),(9.5,74000,1),(4.5,64000,0),(2,54000,0),(1,52000,0),(4,69000,0),(6.5,76000,0),(3,60000,0),(4.5,63000,0),(7.8,70000,0),(3.9,60000,1),(0.8,51000,0),(4.2,78000,0),(1.1,54000,0),(6.2,60000,0),(2.9,59000,0),(2.1,52000,0),(8.2,87000,0),(4.8,73000,0),(2.2,42000,1),(9.1,98000,0),(6.5,84000,0),(6.9,73000,0),(5.1,72000,0),(9.1,69000,1),(9.8,79000,1),]\n",
    "data = [list(row) for row in tuples]\n",
    "\n",
    "xs = [[1.0] + row[:2] for row in data]  # [1, experience, salary]\n",
    "ys = [row[2] for row in data]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "from typing import List, Tuple\n",
    "import random\n",
    "import tqdm\n",
    "Vector = List[float]\n",
    "\n",
    "def add(v: Vector, w: Vector) -> Vector:\n",
    "    \"\"\"Adds corresponding elements\"\"\"\n",
    "    assert len(v) == len(w), \"vectors must be the same length\"\n",
    "\n",
    "    return [v_i + w_i for v_i, w_i in zip(v, w)]\n",
    "\n",
    "def mean(xs: List[float]) -> float:\n",
    "    return sum(xs) / len(xs)\n",
    "\n",
    "def de_mean(xs: List[float]) -> List[float]:\n",
    "    \"\"\"Translate xs by subtracting its mean (so the result has mean 0)\"\"\"\n",
    "    x_bar = mean(xs)\n",
    "    return [x - x_bar for x in xs]\n",
    "\n",
    "def dot(v: Vector, w: Vector) -> float:\n",
    "    \"\"\"Computes v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
    "    assert len(v) == len(w), \"vectors must be same length\"\n",
    "\n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v, w))\n",
    "\n",
    "def variance(xs: List[float]) -> float:\n",
    "    \"\"\"Almost the average squared deviation from the mean\"\"\"\n",
    "    assert len(xs) >= 2, \"variance requires at least two elements\"\n",
    "\n",
    "    n = len(xs)\n",
    "    deviations = de_mean(xs)\n",
    "    return sum_of_squares(deviations) / (n - 1)\n",
    "\n",
    "import math\n",
    "\n",
    "def standard_deviation(xs: List[float]) -> float:\n",
    "    \"\"\"The standard deviation is the square root of the variance\"\"\"\n",
    "    return math.sqrt(variance(xs))\n",
    "\n",
    "def sum_of_squares(v: Vector) -> float:\n",
    "    \"\"\"Returns v_1 * v_1 + ... + v_n * v_n\"\"\"\n",
    "    return dot(v, v)\n",
    "\n",
    "def vector_sum(vectors: List[Vector]) -> Vector:\n",
    "    \"\"\"Sums all corresponding elements\"\"\"\n",
    "    # Check that vectors is not empty\n",
    "    assert vectors, \"no vectors provided!\"\n",
    "\n",
    "    # Check the vectors are all the same size\n",
    "    num_elements = len(vectors[0])\n",
    "    assert all(len(v) == num_elements for v in vectors), \"different sizes!\"\n",
    "\n",
    "    # the i-th element of the result is the sum of every vector[i]\n",
    "    return [sum(vector[i] for vector in vectors)\n",
    "            for i in range(num_elements)]\n",
    "\n",
    "def scalar_multiply(c: float, v: Vector) -> Vector:\n",
    "    \"\"\"Multiplies every element by c\"\"\"\n",
    "    return [c * v_i for v_i in v]\n",
    "\n",
    "def vector_mean(vectors: List[Vector]) -> Vector:\n",
    "    \"\"\"Computes the element-wise average\"\"\"\n",
    "    n = len(vectors)\n",
    "    return scalar_multiply(1/n, vector_sum(vectors))\n",
    "\n",
    "def scale(data: List[Vector]) -> Tuple[Vector, Vector]:\n",
    "    \"\"\"returns the means and standard deviations for each position\"\"\"\n",
    "    dim = len(data[0])\n",
    "\n",
    "    means = vector_mean(data)\n",
    "    stdevs = [standard_deviation([vector[i] for vector in data])\n",
    "              for i in range(dim)]\n",
    "\n",
    "    return means, stdevs\n",
    "\n",
    "def rescale(data: List[Vector]) -> List[Vector]:\n",
    "    \"\"\"\n",
    "    Rescales the input data so that each position has\n",
    "    mean 0 and standard deviation 1. (Leaves a position\n",
    "    as is if its standard deviation is 0.)\n",
    "    \"\"\"\n",
    "    dim = len(data[0])\n",
    "    means, stdevs = scale(data)\n",
    "\n",
    "    # Make a copy of each vector\n",
    "    rescaled = [v[:] for v in data]\n",
    "\n",
    "    for v in rescaled:\n",
    "        for i in range(dim):\n",
    "            if stdevs[i] > 0:\n",
    "                v[i] = (v[i] - means[i]) / stdevs[i]\n",
    "\n",
    "    return rescaled\n",
    "\n",
    "def least_squares_fit(xs: List[Vector],\n",
    "                      ys: List[float],\n",
    "                      learning_rate: float = 0.001,\n",
    "                      num_steps: int = 1000,\n",
    "                      batch_size: int = 1) -> Vector:\n",
    "    \"\"\"\n",
    "    Find the beta that minimizes the sum of squared errors\n",
    "    assuming the model y = dot(x, beta).\n",
    "    \"\"\"\n",
    "    # Start with a random guess\n",
    "    guess = [random.random() for _ in xs[0]]\n",
    "\n",
    "    for _ in tqdm.trange(num_steps, desc=\"least squares fit\"):\n",
    "        for start in range(0, len(xs), batch_size):\n",
    "            batch_xs = xs[start:start+batch_size]\n",
    "            batch_ys = ys[start:start+batch_size]\n",
    "\n",
    "            gradient = vector_mean([sqerror_gradient(x, y, guess)\n",
    "                                    for x, y in zip(batch_xs, batch_ys)])\n",
    "            guess = gradient_step(guess, gradient, -learning_rate)\n",
    "\n",
    "    return guess\n",
    "\n",
    "def predict(x: Vector, beta: Vector) -> float:\n",
    "    \"\"\"assumes that the first element of x is 1\"\"\"\n",
    "    return dot(x, beta)\n",
    "\n",
    "def gradient_step(v: Vector, gradient: Vector, step_size: float) -> Vector:\n",
    "    \"\"\"Moves `step_size` in the `gradient` direction from `v`\"\"\"\n",
    "    assert len(v) == len(gradient)\n",
    "    step = scalar_multiply(step_size, gradient)\n",
    "    return add(v, step)\n",
    "\n",
    "def error(x: Vector, y: float, beta: Vector) -> float:\n",
    "    return predict(x, beta) - y\n",
    "\n",
    "def squared_error(x: Vector, y: float, beta: Vector) -> float:\n",
    "    return error(x, y, beta) ** 2\n",
    "\n",
    "x = [1, 2, 3]\n",
    "y = 30\n",
    "beta = [4, 4, 4]  # so prediction = 4 + 8 + 12 = 24\n",
    "\n",
    "assert error(x, y, beta) == -6\n",
    "assert squared_error(x, y, beta) == 36\n",
    "\n",
    "def sqerror_gradient(x: Vector, y: float, beta: Vector) -> Vector:\n",
    "    err = error(x, y, beta)\n",
    "    return [2 * err * x_i for x_i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|██████████| 1000/1000 [00:01<00:00, 870.03it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "rescaled_xs = rescale(xs)\n",
    "beta = least_squares_fit(rescaled_xs, ys, learning_rate, 1000, 1)\n",
    "\n",
    "predictions = [predict(x_i, beta) for x_i in rescaled_xs]\n",
    "\n",
    "plt.scatter(predictions, ys)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problems**:\n",
    "1. Predicted outputs need to be 0 or 1 or between, linear model have huge positive numbers or even negative numbers\n",
    "2. The linear regression model assumed that the errors were uncorrelated with the columns of x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2 The logistic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x: float) -> float:\n",
    "    return 1.0 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_prime(x: float) -> float:\n",
    "    y = logistic(x)\n",
    "    return y * (1 - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "def _negative_log_likelihood(x: Vector, y: float, beta: Vector) -> float:\n",
    "    '''The negative log likelihood for one data point'''\n",
    "    if y == 1:\n",
    "        return - math.log(logistic(dot(x, beta)))\n",
    "    else:\n",
    "        return - math.log(1 - logistic(dot(x, beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_log_likelihood(xs: List[Vector],\n",
    "                            ys: List[float],\n",
    "                            beta: Vector) -> float:\n",
    "    return sum(_negative_log_likelihood(x, y, beta)\n",
    "               for x, y, in zip(xs, ys))\n",
    "\n",
    "def _negative_log_partial_j(x: Vector, y: float, beta: Vector, j: int) -> float:\n",
    "    '''The jth partial derivative for one data point, here i is the index of the data point'''\n",
    "    return -(y - logistic(dot(x, beta))) * x[j]\n",
    "\n",
    "def _negative_log_gradient(x: Vector, y: float, beta: Vector) -> Vector:\n",
    "    '''The gradient for one data point'''\n",
    "    return [_negative_log_partial_j(x, y, beta, j)\n",
    "            for j in range(len(beta))]\n",
    "\n",
    "def negative_log_gradient(xs: List[Vector],\n",
    "                          ys: List[float],\n",
    "                          beta: Vector) -> Vector:\n",
    "    return vector_sum([_negative_log_gradient(x, y, beta)\n",
    "                       for x, y in zip(xs, ys)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.3 Applying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar, List, Tuple\n",
    "X = TypeVar('X') \n",
    "Y = TypeVar('Y') \n",
    "\n",
    "def split_data(data: List[X], prob: float) -> Tuple[List[X], List[X]]:\n",
    "    \"\"\"Split data into fractions [prob, 1 - prob]\"\"\"\n",
    "    data = data[:]                    # Make a shallow copy\n",
    "    random.shuffle(data)              # because shuffle modifies the list.\n",
    "    cut = int(len(data) * prob)       # Use prob to find a cutoff\n",
    "    return data[:cut], data[cut:]     # and split the shuffled list there.\n",
    "\n",
    "def train_test_split(xs: List[X],\n",
    "                     ys: List[Y],\n",
    "                     test_pct: float) -> Tuple[List[X], List[X], List[Y], List[Y]]:\n",
    "    # Generate the indices and split them.\n",
    "    idxs = [i for i in range(len(xs))]\n",
    "    train_idxs, test_idxs = split_data(idxs, 1 - test_pct)\n",
    "\n",
    "    return ([xs[i] for i in train_idxs],  # x_train\n",
    "            [xs[i] for i in test_idxs],   # x_test\n",
    "            [ys[i] for i in train_idxs],  # y_train\n",
    "            [ys[i] for i in test_idxs])   # y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 39.963 beta:[-2.0239032476251424, 4.693047853942649, -4.469811321910748]: 100%|██████████| 5000/5000 [00:07<00:00, 640.97it/s]  \n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "x_train, x_test, y_train, y_test = train_test_split(rescaled_xs, ys, 0.33)\n",
    "learning_rate = 0.01\n",
    "\n",
    "# pick a random starting point \n",
    "beta = [random.random() for _ in range(3)]\n",
    "\n",
    "with tqdm.trange(5000) as t:\n",
    "    for epoch in t:\n",
    "        gradient = negative_log_gradient(x_train, y_train, beta)\n",
    "        beta = gradient_step(beta, gradient, -learning_rate)\n",
    "        loss = negative_log_likelihood(x_train, y_train, beta)\n",
    "        t.set_description(f'loss: {loss:.3f} beta:{beta}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.0239032476251424, 4.693047853942649, -4.469811321910748]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.927236932527311, 1.6482026277676038, -0.00028768900920142336]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means, stdevs = scale(xs)\n",
    "beta_unscaled = [(beta[0] - beta[1] * means[1] / stdevs[1] - beta[2] * means[2] / stdevs[2]),\n",
    "                 beta[1] / stdevs[1],\n",
    "                 beta[2] / stdevs[2]]\n",
    "beta_unscaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.4 Goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives = false_positives = true_negatives = false_negatives = 0\n",
    "\n",
    "for x_i, y_i in zip(x_test, y_test):\n",
    "    prediction = logistic(dot(beta, x_i))\n",
    "    \n",
    "    if y_i == 1 and prediction >= 0.5: # TP: paid and we predicted paid \n",
    "        true_positives += 1\n",
    "    elif y_i == 1: # FN: paid and we predicted unpaid \n",
    "        false_negatives += 1\n",
    "    elif prediction >= 0.5: # FP: unpaid and we predict paid \n",
    "        false_positives += 1\n",
    "    else: # TN: unpaid and we predict unpaid \n",
    "        true_negatives += 1\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.8\n"
     ]
    }
   ],
   "source": [
    "print(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = [logistic(dot(beta, x_i)) for x_i in x_test]\n",
    "plt.scatter(predictions, y_test, marker = '+')\n",
    "plt.xlabel('predicted probability')\n",
    "plt.ylabel('actual outcome')\n",
    "plt.title('Logistic Regression Predicted vs. Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.5 Support vector machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the hyperplane that best separates the classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.6 For further investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIBSVM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
